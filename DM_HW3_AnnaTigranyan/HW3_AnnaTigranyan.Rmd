---
title: "Homework 3"
author: "Anna Tigranyan"
output: html_document
---
<br>

# Task 1 (40 points): Poisson Regression: Data Cleaning and Description

<br>
<br>
**a.** Load the awards.csv file. Get rid of variables that are irrelevant for Poisson regression analysis using function select(). Pay attention to the last column of your data. Use the separate() function to solve the problem based on data description.<br>

**b.** Check whether the data types are correct, if not, make appropriate corrections, assigning labels to each level according to the data description. Use the glimpse() function to see the structure of the final data.<br>

**c.**Find your dependent variable for Poisson regression analysis. Plot the histogram of your target variable. Calculate the unconditional mean and variance of your target variable. What can you notice?<br>

**d.**Find the categorical variables which affect your target variable using boxplots. Comment on it.<br>

**e.**Use group_by() and summarise() functions to conclude about conditional variances and the means of your target variable grouped by categorical variables. Comment on it: do you have the problem of overdispersion?

-------------------------------------------------------------------------------------

<br>

## a. Load the awards.csv file. Get rid of variables that are irrelevant for Poisson regression analysis using function select(). Pay attention to the last column of your data. Use the separate() function to solve the problem based on data description.


```{r message=FALSE, warning=FALSE, include=FALSE, results="hide"}
library(readr)
library(tidyr)
library(dplyr)
library(ggplot2)
library(AER)
library(MASS)
```

```{r results="hide", message=FALSE, warning=FALSE}
df <- read_csv("awards.csv")
```

```{r}
head(df)
```

```{r}
# Removing irrelevant variables from data 
df <- subset(df, select=-c(...1,id_num,date) )

# Separating last column('school+prog') into 'school' & 'prog'
df = separate(df, col='school+prog', into=c('school', 'prog'), sep='/')
```

```{r}
head(df)
```
<br>

## b. Check whether the data types are correct, if not, make appropriate corrections, assigning labels to each level according to the data description. Use the glimpse() function to see the structure of the final data.<br>

```{r}
glimpse(df)
```
Let's do appropriate changes:

```{r}
# awards is integer (target variable for Poisson regression)
df$awards <- as.integer(df$awards)

# gender, school, progress are factors
df$gender <- factor(df$gender,levels = c('male','female'),labels = c('male','female'))
df$school <- factor(df$school,levels = c('Public','Private'),labels = c('Public','Private'))
df$prog <- factor(df$prog,levels = c(0,1,2,3),
                    labels = c('General','Pre-Academic','Academic','Vocationa'))

#importance is ordered factor
df$imp <- factor(df$imp,levels = c(1,2,3,4),ordered = TRUE)

```

```{r}
glimpse(df)
```


## c.Find your dependent variable for Poisson regression analysis. Plot the histogram of your target variable. Calculate the unconditional mean and variance of your target variable. What can you notice?

<br>
Dependent variable for Poisson regression is **awards**(The number of awards earned by students during high school).It follows a Poisson distribution.Let's look the histogram of our target variable:
```{r message=FALSE, warning=FALSE}
ggplot(data=df,aes(x=awards))+geom_histogram(color="blue", fill="cyan")+
    xlab('Number of awards') + ylab('Count') + 
      ggtitle("The distribution of awards")
```
 <br>
 
```{r}
paste('Mean of awards is:',round(mean(df$awards),2))
paste('Variance of awards is:',round(var(df$awards),2))

```

From above we see that the **mean** and the **variance** of our target variable(awards) are **approximately the same** which is to say that our variable has a Poisson distribution.<br>
<br>


## d.Find the categorical variables which affect your target variable using boxplots. Comment on it.

```{r message=FALSE, warning=FALSE}
ggplot(data=df,aes(x=awards,y=gender))+geom_boxplot(outlier.size=5,outlier.shape=20,
                                                    outlier.colour="red",fill='cyan') +
                  stat_summary(fun.y=mean, geom="point", shape=15, size=5, color="blue")+
                  xlab('Number of awards') + ylab('Gender') + 
                  ggtitle("Awards by Gender")
```
<br>
From above we can notice that:<br>
 -female students get less awards than male students,<br>
 -Outliers (students who get lot of awards) are in male students<br>
So we can say that our target variable is highly dependent on gender.<br> 
```{r message=FALSE, warning=FALSE}
ggplot(data=df,aes(x=awards,y=imp))+geom_boxplot(outlier.size=5,outlier.shape=20,
                                                    outlier.colour="red",fill='cyan') +
                  stat_summary(fun.y=mean, geom="point", shape=15, size=5, color="blue")+
                  xlab('Number of awards') + ylab('Importance') + 
                  ggtitle("Awards by Importance")
```
<br>
From above boxplots we see that when an importance of getting an award is higher the number of awards is high, but this happens when we compare 1-2 with 3-4(In case of 1 compare 2 this is not so)<br>

```{r message=FALSE, warning=FALSE}
ggplot(data=df,aes(x=awards,y=school))+geom_boxplot(outlier.size=5,outlier.shape=20,
                                                    outlier.colour="red",fill='cyan') +
                  stat_summary(fun.y=mean, geom="point", shape=15, size=5, color="blue")+
                  xlab('Number of awards') + ylab('School Type') + 
                  ggtitle("Awards by School Type")
```
<br>
From above we can notice that:<br>
 -Private school students get less awards than Public school students,<br>
 -Outliers (students who get lot of awards) are Private school students<br>
<br>


```{r message=FALSE, warning=FALSE}
ggplot(data=df,aes(x=awards,y=prog))+geom_boxplot(outlier.size=5,outlier.shape=20,
                                                    outlier.colour="red",fill='cyan') +
                  stat_summary(fun.y=mean, geom="point", shape=15, size=5, color="blue")+
                  xlab('Number of awards') + ylab('Program Type') + 
                  ggtitle("Awards by Program Type")
```
<br>
From above we see that there are no significant connection between Program type and our target.
<br>

## e.Use group_by() and summarise() functions to conclude about conditional variances and the means of your target variable grouped by categorical variables. Comment on it: do you have the problem of overdispersion?

```{r}
df %>% group_by(gender) %>% summarise(mean(awards),var(awards))

```

```{r}
df %>% group_by(imp) %>% summarise(mean(awards),var(awards))
```

```{r}
df %>% group_by(school) %>% summarise(mean(awards),var(awards))

```

```{r}
df %>% group_by(prog) %>% summarise(mean(awards),var(awards))

```

We don't have the problem of overdispersion in our cases(we have underdispersion in first 3 cases(grouped by gender,imp,school) and mean=var in last case(grouped by prog)).
<br>

# Task 2 (50 points): Poisson Regression: Modeling

<br> 

**a.** Use the glm() function to perform an intercept-only Poisson regression model with your chosen target variable as the response. Use the output of your model to calculate the mean of your target variable.<br>

**b.**Exclude from full model variables with insignificant coefficients. Show the result. Explain the meanings of coefficients of your model (at least one numeric and one categorical).<br>


**c.**Pick your own new observation and predict the λ. Comment on it.<br>

**d.** Calculate the probability of having more than 15 awards using your predicted λ from Problem 2 c.<br>

**e.** Add to your data a new (created) variable with the problem of unconditional overdispersion.1 Show the problem by computing the average and variance of your variable. (Your variable needs to have a similar meaning to your target variable).<br>

**f.**Run the model with the new variable as a response. Your model must contain only significant coefficients.<br>

**g.**Use the function dispersiontest() to find out overdispersion. Formulate Null and Alternative hypotheses for trafo = Null (mathematically and explain it). Do you have an overdispersion?<br>

**h.**Run the negative binomial and quasi-Poisson model. Show only coefficients. Find the best model based on deviance and AIC. Which is the best model?<br>

<br>


## a.Use the glm() function to perform an intercept-only Poisson regression model with your chosen target variable as the response. Use the output of your model to calculate the mean of your target variable.

```{r}
model <- glm(awards ~ 1, data = df, family = poisson(link = log))
summary(model)
```

```{r}
mean(df$awards)

# Using the output of  model to calculate the mean of our target variable(awards)
exp(model$coefficients)

```


## b.Exclude from full model variables with insignificant coefficients. Show the result. Explain the meanings of coefficients of your model (at least one numeric and one categorical).<br>


```{r}
full_model <- glm(formula = awards ~ ., family = poisson(link = log), data = df)
summary(full_model)
```
From above we see that our significant variables are:<br>
- math<br>
-physics<br>
-hpw<br>
-gender<br>
-imp<br>

Let's construct our best model using this variables as explanatory variables:
```{r}
best_model <- glm(formula = awards ~ math+physics+hpw+gender+imp,
                  family = poisson(link = log), data = df)
summary(best_model)
```

<br>
**math**<br>
If the math exam score increases by one unit(given the other variables are held constant in the model),the awards increase by exp(0.015294)=**1.015412 times**<br>
**physics**<br>
If the physics exam score increases by one unit(given the other variables are held constant in the model),the awards increase by exp(0.011169)=**1.011232 times**<br>
**Gender**<br>
exp(-0.113968)=0.89
Female students receive 11% (0.89 – 1 = -0.11) less awards than male students.
<br>

## c.Pick your own new observation and predict the λ. Comment on it.

```{r}
nd <- data.frame(gender = "female", math = 20.57,physics=19.98,
hpw = 15, imp='3')

as.numeric(lambda <- predict(best_model, newdata = nd,type="response"))
```
<br> 

We see that our model(**best_model**) predicts lambda = 3.57 and it means that if we pick an observation obs = (gender = "female", math = 20.57,physics=19.98,hpw = 15, imp='3') it is most likely it will belong to the Poisson distribution with lambda =  3.57<br>

## d.Calculate the probability of having more than 15 awards using your predicted λ from Problem 2 c.

```{r}
ppois(15, lambda = lambda, lower.tail = F)
```
The probability of having more than 15 awards using  λ=3.57 is too small.<br>


## e.Add to your data a new (created) variable with the problem of unconditional overdispersion. Show the problem by computing the average and variance of your variable. (Your variable needs to have a similar meaning to your target variable)


```{r}

 set.seed(100)

new_var <- rnbinom(length(df$awards), size = 5,mu=3.57)
df$new_var <- new_var
head(df)
```
```{r}
unique(df$new_var)
```

```{r}
df %>% summarise(mean(new_var),var(new_var)) 

```
<br>


## f.Run the model with the new variable as a response. Your model must contain only significant coefficients.

<br>
```{r}
new_full_model <- glm(formula = new_var ~ ., family = poisson(link = log), data = df)
summary(new_full_model)

```

<br>
Let's choose significant variables from full model and construct new_best_model:

```{r}
new_best_model <- glm(formula = new_var ~ math+prog+physics, family = poisson(link = log), data = df)
summary(new_best_model)

```

<br>


## g. Use the function dispersiontest() to find out overdispersion. Formulate Null and Alternative hypotheses for trafo = Null (mathematically and explain it). Do you have an overdispersion?
<br>
```{r}
dispersiontest(new_best_model, trafo = NULL)
```
The standard Poisson GLM models the (conditional) mean E[y] = mu which is assumed to be equal to the variance VAR[y] = mu. dispersiontest assesses the hypothesis that this assumption holds (equidispersion) against the alternative that the variance is of the form:<br>
<br>
**VAR[y] = mu + alpha x trafo(mu).**<br>
<br>
-Overdispersion corresponds to alpha > 0 <br>
underdispersion to alpha < 0.<br>
Common specifications of the transformation function trafo are **trafo(mu) = mu^2** or **trafo(mu) = mu**. The former corresponds to a negative binomial (NB) model with quadratic variance function , the latter to a NB model with linear variance function or quasi-Poisson model with dispersion parameter.
<br>
**VAR[y]** = (1 + alpha) x mu = **dispersion x mu**.
<br>
By default, for trafo = NULL, the latter dispersion formulation is used in dispersiontest, which is our case.<br>
From test we see that dispersion is 1.6 which means that VAR[y] = 1.6 * mu, so Var[y] > mu and **we have overispersion.**


 <br>
 
 
## h.Run the negative binomial and quasi-Poisson model. Show only coefficients. Find the best model based on deviance and AIC. Which is the best model?

```{r}
model_quasi <- glm(new_var ~ math + prog + physics, family = quasipoisson(link = log), data = df)
model_nb <- glm.nb(new_var ~ math + prog + physics, data = df)

data.frame(coef(new_best_model), coef(model_quasi), coef(model_nb))
```



If we compare new_best_model and model_nb based on AIC: <br>
**new_best_model** - AIC = **11405**<br>
**model_nb** - AIC = **11067**<br>
model_nb is better model because AIC value is smaller.<br>

<br>
Let's compare model_nb and model_quasi based on deviance:<br>
**model_quasi**-Residual deviance: **4311.5**  
**model_nb**-Residual deviance: **2785.6** <br>
model_nb is better model because deviance is smaller.<br>
<br>


# Questions (10 points)
<br>
**a.**What is the equidispersion in Poisson regression? Why do we need to avoid overdispersion?
<br>


**b**Why Poisson regression is called log-linear?
<br>


## a.What is the equidispersion in Poisson regression? Why do we need to avoid overdispersion?
<br>

One feature of the Poisson distribution(and Posisson regression) is that the mean equals the variance(equidispersion). However, over- or underdispersion happens in Poisson models, where the variance is larger or smaller than the mean value, respectively. In reality, overdispersion happens more frequently with a limited amount of data.
We need to avoid overdispersion because it does not meet the condition of Poisson regression(mean= var for target variable) and we need other models to solve this problem.
<br>

# b.Why Poisson regression is called log-linear?
<br>

Poisson regression is called log-linear because of it formula:<br>
Poisson rate parameter λi is given by <br>
log(λi) = β0 + β1xi1 + . . . + βpxip,<br>
or equivalently,<br>
λi = exp(β0+β1xi1+...+βpxip)<br>
Together with the distributional assumption Yi ∼ Poisson(λi), this is called the **Poisson
log-linear** model, or the **Poisson regression model**.








